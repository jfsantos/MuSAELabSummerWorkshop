{
 "metadata": {
  "name": "",
  "signature": "sha256:4390e37de2c886c91f16769f18f532d7799f1f46b04ad4e13ebd51c91f8db621"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Best practices - code examples\n",
      "-----------------------------\n",
      "\n",
      "Here's a simple experiment: we want to load a dataset, train an SVM using half of the samples, test it with the other half, and report accuracy. The script below would be a first approach (probably something you would write interactively in an IPython notebook or shell)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "from sklearn import svm\n",
      "import numpy as np\n",
      "\n",
      "digits = cPickle.load(open(\"digits.pkl\"))\n",
      "X = digits.images.reshape((digits.images.shape[0], -1))\n",
      "y = digits.target\n",
      "\n",
      "idx = np.random.permutation(X.shape[0])\n",
      "Xtr = X[idx[0:len(idx)/2]]\n",
      "Xts = X[idx[(len(idx)/2):]]\n",
      "ytr = y[idx[0:len(idx)/2]]\n",
      "yts = y[idx[(len(idx)/2):]]\n",
      "\n",
      "c = svm.LinearSVC(C=1.0)\n",
      "c.fit(Xtr, ytr)\n",
      "\n",
      "y_hat = c.predict(Xts)\n",
      "\n",
      "acc = float(sum(y_hat == yts))/len(yts)\n",
      "print \"Accuracy is %1.4f\" % acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy is 0.9288\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write programs for people, not computers!\n",
      "--------------\n",
      "\n",
      "\n",
      "- Fixed random seed\n",
      "- Add more descriptive names to variables\n",
      "- Split into functions (load_data, train, test)\n",
      "- Data file and hyperparameters as function parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "from sklearn import svm\n",
      "import numpy as np\n",
      "\n",
      "def load_data(path, test_size):\n",
      "    digits = cPickle.load(open(\"digits.pkl\"))\n",
      "    X = digits.images.reshape((digits.images.shape[0], -1))\n",
      "    y = digits.target\n",
      "\n",
      "    idx = np.random.permutation(X.shape[0])\n",
      "    n_train_samples = int(round(len(X)*(1-test_size)))\n",
      "    \n",
      "    X_train = X[idx[0:n_train_samples]]\n",
      "    X_test = X[idx[n_train_samples:]]\n",
      "    y_train = y[idx[0:n_train_samples]]\n",
      "    y_test = y[idx[n_train_samples:]]\n",
      "    return X_train, y_train, X_test, y_test\n",
      "\n",
      "def train(X_train, y_train, C, loss):\n",
      "    classifier = svm.LinearSVC(C=C, loss=loss)\n",
      "    classifier.fit(X_train, y_train)\n",
      "    return classifier\n",
      "\n",
      "def test(classifier, X, y):\n",
      "    y_hat = classifier.predict(X)\n",
      "    acc = float(sum(y_hat == y_test))/len(y_test)\n",
      "    return y_hat, acc\n",
      "\n",
      "# Experiment parameters\n",
      "datapath = \"digits.pkl\"\n",
      "test_size = 0.5\n",
      "svm_C = 1.0\n",
      "svm_loss = \"l2\"\n",
      "random_seed = 42\n",
      "\n",
      "np.random.seed(random_seed)\n",
      "X_train, y_train, X_test, y_test = load_data(datapath, test_size)\n",
      "classifier = train(X_train, y_train, svm_C, svm_loss)\n",
      "y_hat, acc = test(classifier, X_test, y_test)\n",
      "\n",
      "print \"Accuracy is %1.4f\" % acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy is 0.9276\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let the computer do the work & don't repeat yourself!\n",
      "-------------\n",
      "\n",
      "- Moved functions to module, so they can be reused in other experiments\n",
      "- Automated parameter exploration\n",
      "- Storing results in a dictionary and saving it to a file (so we have a \"table\" with results and corresponding parameters)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Code in svm_digits.py\n",
      "import cPickle\n",
      "from sklearn import svm\n",
      "import numpy as np\n",
      "\n",
      "def load_data(path, test_size, random_seed):\n",
      "    np.random.seed(random_seed)\n",
      "    digits = cPickle.load(open(\"digits.pkl\"))\n",
      "    X = digits.images.reshape((digits.images.shape[0], -1))\n",
      "    y = digits.target\n",
      "\n",
      "    idx = np.random.permutation(X.shape[0])\n",
      "    n_train_samples = int(round(len(X)*(1-test_size)))\n",
      "    \n",
      "    X_train = X[idx[0:n_train_samples]]\n",
      "    X_test = X[idx[n_train_samples:]]\n",
      "    y_train = y[idx[0:n_train_samples]]\n",
      "    y_test = y[idx[n_train_samples:]]\n",
      "    return X_train, y_train, X_test, y_test\n",
      "\n",
      "def train(X_train, y_train, C, loss):\n",
      "    classifier = svm.LinearSVC(C=C, loss=loss)\n",
      "    classifier.fit(X_train, y_train)\n",
      "    return classifier\n",
      "\n",
      "def test(classifier, X, y):\n",
      "    y_hat = classifier.predict(X)\n",
      "    acc = float(sum(y_hat == y))/len(y)\n",
      "    return y_hat, acc\n",
      "\n",
      "def run_experiment(random_seed, data, C, loss):\n",
      "    np.random.seed(random_seed)\n",
      "    X_train, y_train, X_test, y_test = data\n",
      "    classifier = train(X_train, y_train, C, loss)\n",
      "    y_hat, acc = test(classifier, X_test, y_test)\n",
      "    return y_hat, acc\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from svm_digits import *\n",
      "import itertools, cPickle\n",
      "\n",
      "# Fixed parameters (across all experiments)\n",
      "datapath = \"digits.pkl\"\n",
      "test_size = 0.5\n",
      "random_seed = 42\n",
      "\n",
      "data = load_data(datapath, test_size, random_seed)\n",
      "\n",
      "# Hyperparameter optimization\n",
      "svm_C = [0.1, 0.5, 1.0]\n",
      "svm_loss = [\"l2\", \"l1\"]\n",
      "\n",
      "experiments = []\n",
      "\n",
      "for C, loss in itertools.product(svm_C, svm_loss):\n",
      "    exp = {}\n",
      "    exp['C'] = C\n",
      "    exp['loss'] = loss\n",
      "    y_hat, acc = run_experiment(random_seed, data, C, loss) \n",
      "    exp['acc'] = acc\n",
      "    experiments.append(exp)\n",
      "    \n",
      "# Note that the following line will always save the results to the same file.\n",
      "# What's the problem here? \n",
      "cPickle.dump(experiments, open(\"results_hyperopt.pkl\", \"w\"))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "experiments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[{'C': 0.1, 'acc': 0.9342984409799554, 'loss': 'l2'},\n",
        " {'C': 0.1, 'acc': 0.9220489977728286, 'loss': 'l1'},\n",
        " {'C': 0.5, 'acc': 0.9265033407572383, 'loss': 'l2'},\n",
        " {'C': 0.5, 'acc': 0.9242761692650334, 'loss': 'l1'},\n",
        " {'C': 1.0, 'acc': 0.920935412026726, 'loss': 'l2'},\n",
        " {'C': 1.0, 'acc': 0.9242761692650334, 'loss': 'l1'}]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Don't repeat others!\n",
      "--------------\n",
      "\n",
      "- The `sklearn` library has functions to split datasets in the `cross_validation` module.\n",
      "- Chances are these libraries will do exactly what we want, which will save us time because:\n",
      "    - We don't have to *write* the code\n",
      "    - We don't have to *test* the code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Update svm_digits with the following:\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "def load_data(path, test_size, random_seed):\n",
      "    digits = cPickle.load(open(\"digits.pkl\"))\n",
      "    X = digits.images.reshape((digits.images.shape[0], -1))\n",
      "    y = digits.target\n",
      "    sets = train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
      "    return sets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = load_data('digits.pkl', 0.5, 42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plan for mistakes\n",
      "-----------------\n",
      "\n",
      "- If something can't be done, make sure the program does not let the user do it!\n",
      "- Demo of testing with `Nose` and interactive debugging using Spyder (IPython notebooks do not support interactive debugging)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimization\n",
      "------------\n",
      "\n",
      "- Profiling is a more complicated topic and we will not talk about it today. Let me know if you are interested and I'll give you some pointers.\n",
      "- Sometimes Python is too slow and we need to write or use faster code (written in C or Fortran, for example) or paralellize our code.\n",
      "- However, always start with the simplest, highest-level code that does the job. It will be easier to debug and you can use it as a reference later when writing your optimized version.\n",
      "- There are some cool tools to accelerate Python code (Numba, Parakeet, Theano), but these are advanced topics. Again, let me know if you are interested!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Document Design and Purpose, Not Mechanics\n",
      "------------------------------------------\n",
      "\n",
      "If you took any basic software engineering course, you probably know this joke (sorry!)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "\n",
      "# insert code doing something interesting here...\n",
      "\n",
      "i = i + 1 # increment i by 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You want comments like this, instead:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_data(path, test_size, random_seed):\n",
      "    ''' Loads the data file (in pickle format) from `path` and splits it\n",
      "    into training and testing partitions. The testing partition will have\n",
      "    `test_size` * #samples, and the training partition (1-`test_size`) * #samples.\n",
      "    Samples are shuffled before partitioning, and `random_seed` will be used as \n",
      "    the random state for the random number generator, so two calls with the same\n",
      "    seed will return exactly the same partitions.\n",
      "    \n",
      "    Example\n",
      "    -------\n",
      "    \n",
      "    X_train, X_test, y_train, y_test = load_data('myfile.pkl', 0.2, 51)'''\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bonus: comments like this in your code are recognized by the Python interpreter (and the IPython ones, of course). They can also be used to automatically generate a documentation website for your code!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_data?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Refactor code in preference to explaining how it works\n",
      "---------------------\n",
      "\n",
      "Any line of code that is so complex it needs a whole paragraph to explain it should be rewritten (remember, write code for humans!). There are code obfuscation contests around if you want to show off with your fancy one-liners :)\n",
      "\n",
      "Let's say you need a dictionary where the keys are the characters from 'a' to 'e' and the values are the position of each character in the alphabet. You could write this one-liner:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = dict(zip('abcde', map(lambda x: x+1, range(5))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or three lines that make sense without the need of a whole paragraph to explain what they do:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = dict()\n",
      "for index, item in enumerate('abcde'):\n",
      "    x[item] = index + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    }
   ],
   "metadata": {}
  }
 ]
}